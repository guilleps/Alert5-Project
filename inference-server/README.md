El servidor de inferencia utiliza el binario `.keras` de nuestro modelo de machine learning seleccionado tras varias pruebas. Este modelo se encuentra dentro del archivo comprimido llamado `modelo_nn.keras`, el cual puedes descargar desde el siguiente enlace:

[Descargar modelo_nn.keras](https://drive.google.com/drive/folders/1oREsKSyyZ99m6BGAd-9mVaQgxr5Hcltu?usp=drive_link)

Una vez descargado, descomprime el archivo y coloca el binario en la carpeta ra√≠z del directorio `inference-server/`.