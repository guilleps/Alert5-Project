# -*- coding: utf-8 -*-
"""tests clasificaion ML_Proyecto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xREMiWEMdgMX0ULlJCa2xeEtLl5VPcb7

# Preprocesamiento de datos

## Exploración

### 1. Importamos las librerias necesarias
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### 2. Importar csv de datos y almacenarlo en un df"""

csv_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vT0XNVWheGuEy463sNLwSPbZ6m0372Lg_3T5Uuuf79e238qbo2zGAuylu_xG1DkpKucTtVoa4xCKGxt/pub?output=csv"
df = pd.read_csv(csv_url)

"""### 3. Información general

#### 3.1. Informacion de los datos del df
"""

df.info()

"""#### 3.2. Mostrar los tipos de datos del df"""

print("\nTipos de datos:")
print(df.dtypes)

"""#### 3.3. Mostrar las primeras filas"""

print("\nPrimeras filas:")
print(df.head())

"""#### 3.4. Mostrar cantidad de filas y columnas"""

print(f"Cantidad de filas y columnas: {df.shape}")

"""### 4. Estadísticos generales

#### 4.1. Estadisticas numéricas
"""

print("\nResumen numérico:")
print(df.describe())

"""#### 4.2. Estadisticas categórica"""

print("\nResumen categórico:")
print(df.describe(include=['object', 'category']))

"""### 5. Revisión de nulos, duplicados y atípicos

#### 5.1. Cantidades de valores nulos
"""

print("\nNulos por columna:")
print(df.isnull().sum())

"""#### 5.2. Porcentaje de valores nulos"""

print("\nPorcentaje de nulos por columna:")
print((df.isnull().sum() / len(df)) * 100)

"""#### 5.3. Cantidad de filas duplicadas"""

print(f"\nFilas duplicadas: {df.duplicated().sum()}")

"""#### 5.4. Identificar Datos Atipicos"""

indices_outliers = set()

for col in ['cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO']:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    limite_superior = Q3 + 1.5 * IQR

    outliers = df[df[col] > limite_superior]
    indices_outliers.update(outliers.index)

total_outliers = len(indices_outliers)
total_registros = len(df)
porcentaje_outliers = (total_outliers / total_registros) * 100

print(f"→ Registros únicos con al menos un valor atípico: {total_outliers} / {porcentaje_outliers:.2f}%")

df_sin_id = df.drop(columns=['id'], errors='ignore')

# Gráfico de boxplot solo para columnas numéricas relevantes
plt.figure(figsize=(12, 6))
sns.boxplot(data=df_sin_id, orient='h')
plt.title("Detección de Outliers por Boxplot (sin id)")
plt.xlabel("Valores")
plt.tight_layout()
plt.show()

"""#### 5.5. Mostrar los registros con los valores más altos por columna de interés"""

columnas_outliers = ['cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO']

for col in columnas_outliers:
    print(f"\n-> Top 5 valores más altos en '{col}':")
    print(df[[col, 'tipo_ocurrencia']].sort_values(by=col, ascending=False).head(5))

"""#### 5.6. Calcular y mostrar la cantidad y porcentaje de outliers por columna"""

outliers_resumen = {}
total_registros = len(df)

for col in ['cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO']:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    limite_superior = Q3 + 1.5 * IQR

    outliers = df[df[col] > limite_superior]
    cantidad = outliers.shape[0]
    porcentaje = (cantidad / total_registros) * 100

    outliers_resumen[col] = {'cantidad': cantidad, 'porcentaje': porcentaje}

print("-> Cantidad y porcentaje de outliers por columna:")
for col, datos in outliers_resumen.items():
    print(f"{col}: {datos['cantidad']} registros ({datos['porcentaje']:.2f}%)")

"""### 6. Valores únicos en columnas clave (categorías relevantes)"""

columnas_clave = ['zona', 'sector', 'tipo_ocurrencia', 'turno', 'pais', 'region', 'provincia', 'distrito']
for col in columnas_clave:
    print(f"\n-> Valores únicos en '{col}':")
    print(df[col].value_counts(dropna=False))

"""### 7. Correlaciones entre variables

#### 7.1. Correlaciones entre variables numéricas
"""

corr = df.select_dtypes(include=[np.number]).corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Mapa de calor de correlaciones numéricas")
plt.show()

"""#### 7.1. Correlaciones entre variables categóricas"""

from scipy.stats import chi2_contingency

# Seleccionar solo columnas categóricas)
categorical_cols = ['zona', 'sector', 'tipo_ocurrencia', 'turno', 'pais', 'region', 'provincia', 'distrito']

# Crear matriz vacía
cramers_v_matrix = pd.DataFrame(index=categorical_cols, columns=categorical_cols)

# Función para calcular Cramér's V
def cramers_v(x, y):
    confusion_matrix = pd.crosstab(x, y)
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    phi2_corr = max(0, phi2 - ((k - 1)*(r - 1)) / (n - 1))
    r_corr = r - ((r - 1)**2) / (n - 1)
    k_corr = k - ((k - 1)**2) / (n - 1)
    return np.sqrt(phi2_corr / min((k_corr - 1), (r_corr - 1)))

# Llenar la matriz
for col1 in categorical_cols:
    for col2 in categorical_cols:
        if col1 == col2:
            cramers_v_matrix.loc[col1, col2] = 1.0
        else:
            v = cramers_v(df[col1], df[col2])
            cramers_v_matrix.loc[col1, col2] = round(v, 2)

# Convertir a float
cramers_v_matrix = cramers_v_matrix.astype(float)

# Graficar
plt.figure(figsize=(10, 8))
sns.heatmap(cramers_v_matrix, annot=True, cmap="YlGnBu", fmt=".2f")
plt.title("Mapa de calor de correlaciones entre variables categóricas (Cramér's V)")
plt.tight_layout()
plt.show()

"""### 8. Visualización de datos

#### 8.1. Distribución de variables numéricas
"""

# Seleccionar variables numéricas
columnas_numericas = df.select_dtypes(include='number').columns

fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))
axs = axs.flatten()

# Histograma por cada variable
for i, col in enumerate(columnas_numericas):
    axs[i].hist(df[col], bins=30, color='teal', edgecolor='black')
    axs[i].set_title(f'Distribución: {col}')
    axs[i].set_xlabel(f'Valor de {col}')
    axs[i].set_ylabel('Cantidad de registros')

plt.suptitle("Distribución de variables numéricas", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""#### 8.2. Incidentes por zona y año"""

import matplotlib.colors as mcolors

# Función para truncar colormap
def truncate_colormap(cmap, minval=0.3, maxval=1.0, n=100):
    return mcolors.LinearSegmentedColormap.from_list(
        f"trunc({cmap.name},{minval:.2f},{maxval:.2f})",
        cmap(np.linspace(minval, maxval, n))
    )

# Obtener colormap compatible
cmap_oscuro = truncate_colormap(plt.get_cmap('Reds'))

# Asegurar tipo datetime
df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
df_filtrado = df[(df['fecha'].dt.year >= 2021) & (df['fecha'].dt.year <= 2024)].copy()
df_filtrado['año'] = df_filtrado['fecha'].dt.year

# Agrupar
zona_anio = df_filtrado.groupby(['zona', 'año'], observed=False).size().unstack(fill_value=0)

# Graficar
zona_anio.plot(kind='bar', figsize=(10, 6), colormap=cmap_oscuro)
plt.title("Distribución de incidentes por zona y año (2021–2024)")
plt.xlabel("Zona")
plt.ylabel("Cantidad de incidentes")
plt.xticks(rotation=0)
plt.legend(title="Año", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""#### 8.3. Incidentes por turno y tipo"""

# Paso 1: top 5 tipos de ocurrencia
top_ocurrencias = df['tipo_ocurrencia'].value_counts().head(5).index.tolist()

# Paso 2: filtrar el DataFrame
df_top = df[df['tipo_ocurrencia'].isin(top_ocurrencias)]

# Paso 3: agrupar y reordenar por frecuencia real
turno_tipo = (
    df_top.groupby(['turno', 'tipo_ocurrencia'], observed=False)
    .size()
    .unstack(fill_value=0)[top_ocurrencias]
)

# Paso 4: truncar colormap
def truncate_colormap(cmap, minval=0.3, maxval=1.0, n=100):
    return mcolors.LinearSegmentedColormap.from_list(
        f"trunc({cmap.name},{minval:.2f},{maxval:.2f})",
        cmap(np.linspace(minval, maxval, n))
    )

cmap_blues_oscuro = truncate_colormap(plt.get_cmap('Blues'))

# Paso 5: graficar
turno_tipo.plot(kind='bar', figsize=(10, 6), colormap=cmap_blues_oscuro)
plt.title("Distribución de los 5 principales tipos de incidentes por turno")
plt.xlabel("Turno")
plt.ylabel("Cantidad de incidentes")
plt.xticks(rotation=0)
plt.legend(title='Tipo de ocurrencia', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""#### 8.4.. Distribución de agentes por zona y turno"""

pivot_heatmap = df.pivot_table(index='zona', columns='turno', values='cantidad_agentes', aggfunc='sum')

plt.figure(figsize=(10, 6))
sns.heatmap(pivot_heatmap, annot=True, fmt=".0f", cmap='Greens')
plt.title("Total de agentes asignados por zona y turno")
plt.xlabel("Turno")
plt.ylabel("Zona")
plt.tight_layout()
plt.show()

"""#### 8.5. Distribución de agentes por sector"""

agente_sector = df.groupby('sector')[['CHOFER', 'CAMINANTE', 'MOTORIZADO']].sum()
agente_sector['total'] = agente_sector.sum(axis=1)

sectores_principales = agente_sector.sort_values('total', ascending=False).drop(columns='total').head(10)

labels = sectores_principales.index
categories = sectores_principales.columns
num_vars = len(labels)
angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
angles += angles[:1]

plt.figure(figsize=(8, 6))
for tipo_agente in categories:
    valores = sectores_principales[tipo_agente].tolist()
    valores += valores[:1]
    plt.polar(angles, valores, label=tipo_agente)
    plt.fill(angles, valores, alpha=0.1)

plt.title("Distribución de agentes por sector", y=1.1)
plt.xticks(angles[:-1], labels, fontsize=9)
plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
plt.tight_layout()
plt.show()

"""#### 8.6. Distribución de agentes por turno"""

agente_sector = df.groupby('turno')[['CHOFER', 'CAMINANTE', 'MOTORIZADO']].sum()
agente_sector['total'] = agente_sector.sum(axis=1)

sectores_principales = agente_sector.sort_values('total', ascending=False).drop(columns='total')

labels = sectores_principales.index
categories = sectores_principales.columns
num_vars = len(labels)
angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
angles += angles[:1]

plt.figure(figsize=(8, 6))
for tipo_agente in categories:
    valores = sectores_principales[tipo_agente].tolist()
    valores += valores[:1]
    plt.polar(angles, valores, label=tipo_agente)
    plt.fill(angles, valores, alpha=0.1)

plt.title("Distribución de agentes por turno", y=1.1)
plt.xticks(angles[:-1], labels, fontsize=9)
plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
plt.tight_layout()
plt.show()

"""## Limpieza

"""

csv_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vT0XNVWheGuEy463sNLwSPbZ6m0372Lg_3T5Uuuf79e238qbo2zGAuylu_xG1DkpKucTtVoa4xCKGxt/pub?output=csv"
df_preETL  = pd.read_csv(csv_url)

"""### 9. Seleccionar las columnas útiles"""

columnas_utiles = [
    'zona', 'sector', 'turno', 'fecha',
    'tipo_ocurrencia', 'cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO'
]

df = df[[col for col in df.columns if col in columnas_utiles]].copy()

print("-> DataFrame reducido a columnas útiles para modelado.")
print(df.head())

"""### 10. Validación y limpieza de columnas vacias

#### 10.1. Comprobar valores nulos
"""

# Calcular cantidad y porcentaje de nulos por columna
nulos_por_columna = df.isnull().sum()
porcentaje_nulos = (nulos_por_columna / len(df)) * 100

# Unir ambos resultados en un DataFrame resumen
resumen_nulos = pd.DataFrame({
    'Cantidad de nulos': nulos_por_columna,
    'Porcentaje de nulos (%)': porcentaje_nulos.round(2)
})

print("Resumen de nulos por columna en DataFrame reducido:")
print(resumen_nulos)

# Total de valores nulos antes de la limpieza
total_nulos_antes = df.isnull().sum().sum()
total_filas_antes = len(df)
porcentaje_antes = (total_nulos_antes / total_filas_antes) * 100
print(f"\nTotal de valores nulos antes de la limpieza: {total_nulos_antes} / {total_filas_antes} ({porcentaje_antes:.2f} %) registros")

"""#### 10.2. Comprar los valores nulos de zonas sean los mismos que los de sector

Filtrar registros donde zona es nulo pero sector no
"""

zona_nula_sector_presente = df[df['zona'].isnull() & df['sector'].notnull()]

# Mostrar cuántos casos cumplen esa condición
print(f"Registros con zona nula pero sector presente: {len(zona_nula_sector_presente)}")

# Mostrar ejemplos para inspección
print(zona_nula_sector_presente[['zona', 'sector']].drop_duplicates().head(10))

"""Filtrar registros donde sector es nulo pero zona no"""

sector_nulo_zona_presente = df[df['sector'].isnull() & df['zona'].notnull()]

# Mostrar cuántos casos cumplen esa condición
print(f"Registros con sector nulo pero zona presente: {len(sector_nulo_zona_presente)}")

# Mostrar ejemplos para inspección
print(sector_nulo_zona_presente[['zona', 'sector']].drop_duplicates().head(10))

"""#### 10.3. Eliminar valores nulos de las columnas zona y sector"""

df = df.dropna(subset=['zona', 'sector'])

# Total de valores nulos después de la limpieza
total_nulos_despues = df.isnull().sum().sum()
total_filas_despues = len(df)
porcentaje_despues = (total_nulos_despues / total_filas_despues) * 100

print(f"Total de valores nulos antes de la limpieza: {total_nulos_antes} / {total_filas_antes} ({porcentaje_antes:.2f} %) registros")
print(f"Total de valores nulos después de la limpieza: {total_nulos_despues} / {total_filas_despues} ({porcentaje_despues:.2f} %) registros")

"""#### 10.4. Comprobar los valores nulos en fecha"""

df[df['fecha'].isnull()]

"""Reemplazar valores nulos por relleno por proximidad"""

# Rellenar nulos en 'fecha' hacia adelante y luego hacia atrás de forma segura
df.loc[:, 'fecha'] = df['fecha'].ffill()
df.loc[:, 'fecha'] = df['fecha'].bfill()

# Verificar nulos restantes
print(f"Nulos restantes en 'fecha': {df['fecha'].isnull().sum()}")

# Información general de nulos
total_nulos_antes = df.isnull().sum().sum()
total_filas_antes = len(df)
porcentaje_antes = (total_nulos_antes / total_filas_antes) * 100
print(f"\n-> Total de valores nulos despues de la limpieza: {total_nulos_antes} / {total_filas_antes} ({porcentaje_antes:.2f} %) registros")

"""#### 10.5. Comparar outliers

Detectar outliers usando la regla IQR
"""

Q1 = df['cantidad_agentes'].quantile(0.25)
Q3 = df['cantidad_agentes'].quantile(0.75)
IQR = Q3 - Q1
limite_superior = Q3 + 1.5 * IQR

# Filtrar registros outliers
outliers = df[df['cantidad_agentes'] > limite_superior]

# Obtener los top 10 incidentes con mayor cantidad de agentes
top_outliers = outliers.sort_values('cantidad_agentes', ascending=False).head(10)

# Mostrar registros con más agentes
print("Top 10 incidentes con mayor cantidad de agentes:")
print(top_outliers[['zona', 'sector', 'turno', 'tipo_ocurrencia', 'cantidad_agentes']])

"""Calcular promedio y cantidad de registros similares"""

print("\nPromedio y cantidad de incidentes registrados con las mismas características:")
for _, row in top_outliers.iterrows():
    filtro = (
        (df['tipo_ocurrencia'] == row['tipo_ocurrencia']) &
        (df['sector'] == row['sector']) &
        (df['turno'] == row['turno']) &
        (df['zona'] == row['zona'])
    )
    promedio = df[filtro]['cantidad_agentes'].mean()
    cantidad = df[filtro].shape[0]
    print(f"- {row['tipo_ocurrencia']} | Zona: {row['zona']} | Sector: {row['sector']} | Turno: {row['turno']} → Promedio: {promedio:.2f} | Casos registrados: {cantidad}")

"""#### 10.6. Crear bandera de outliers"""

df['registro_atipico'] = 0  # Por defecto, no es outlier

# Evaluar outliers en columnas numéricas clave
for col in ['cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO']:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    limite_superior = Q3 + 1.5 * IQR

    # Marcar como outlier
    df.loc[df[col] > limite_superior, 'registro_atipico'] = 1

print("-> Ejemplo de registros normales (registro_atipico = 0):")
print(df[df['registro_atipico'] == 0].head(3)[['zona', 'sector', 'turno', 'tipo_ocurrencia', 'cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO', 'registro_atipico']])

print("\n-> Ejemplo de registros atípicos (registro_atipico = 1):")
print(df[df['registro_atipico'] == 1].head(3)[['zona', 'sector', 'turno', 'tipo_ocurrencia', 'cantidad_agentes', 'CHOFER', 'CAMINANTE', 'MOTORIZADO', 'registro_atipico']])

"""### 11. Datos inconsistentes

#### 11.1. Eliminar datos inconsistentes
"""

# Limpieza de datos inválidos
df = df[
    (df['cantidad_agentes'] >= 0) &
    (df['CHOFER'] >= 0) &
    (df['CAMINANTE'] >= 0) &
    (df['MOTORIZADO'] >= 0)
]

# Validar suma de agentes
df['suma_agentes'] = df['CHOFER'] + df['CAMINANTE'] + df['MOTORIZADO']
df = df[df['cantidad_agentes'] == df['suma_agentes']]
df = df.drop(columns='suma_agentes')

# Filtrar turnos válidos
df = df[df['turno'].isin(['Mañana', 'Tarde', 'Noche'])]

# Limitar a fechas entre 2021 y 2024
df = df[(df['fecha'].dt.year >= 2021) & (df['fecha'].dt.year <= 2024)]

print("-> Datos inconsistentes corregidos y registros inválidos eliminados.")
print(f"-> Registros finales: {len(df)}")

"""#### 11.2. Verificación de datos inconsistentes"""

print("Verificación de datos inconsistentes por columna:\n")

# 1. Valores negativos
negativos = df[
    (df['cantidad_agentes'] < 0) |
    (df['CHOFER'] < 0) |
    (df['CAMINANTE'] < 0) |
    (df['MOTORIZADO'] < 0)
]
print(f"-> Valores negativos: {len(negativos)}")

# 2. Suma de agentes distinta a cantidad_agentes
suma_incorrecta = df[
    (df['CHOFER'] + df['CAMINANTE'] + df['MOTORIZADO']) != df['cantidad_agentes']
]
print(f"-> Suma incorrecta de agentes: {len(suma_incorrecta)}")

# 3. Turnos inválidos
turnos_invalidos = df[~df['turno'].isin(['Mañana', 'Tarde', 'Noche'])]
print(f"-> Turnos inválidos: {len(turnos_invalidos)}")

# 54. Fechas fuera del rango 2021–2024
fechas_fuera_rango = df[(df['fecha'].dt.year < 2021) | (df['fecha'].dt.year > 2024)]
print(f"-> Fechas fuera del rango 2021–2024: {len(fechas_fuera_rango)}")

"""## Transformación

### 13. Estandarizar texto

#### 13.1. Renombrar columnas
"""

import re

def estandarizar_nombre(col):
    # Insertar guiones bajos entre palabras en camelCase
    col = re.sub(r'(?<=[a-z])(?=[A-Z])', '_', col)
    # Reemplazar espacios y guiones por guion bajo
    col = re.sub(r'[\s\-]+', '_', col)
    # Pasar a minúscula
    col = col.lower()
    return col

# Aplicar a todas las columnas
df.columns = [estandarizar_nombre(col) for col in df.columns]

# Verificar columnas nuevas
print("-> Nuevos nombres de columnas:")
print(df.columns.tolist())

"""#### 13.2. Renombrar filas"""

# Detectar columnas tipo 'object' (texto)
columnas_texto = df.select_dtypes(include='object').columns

# Aplicar .str.title() a cada columna de texto
for col in columnas_texto:
    df[col] = df[col].str.strip().str.title()

# Verificar resultado en columnas afectadas
print("-> Contenido de columnas de texto estandarizado:")
print(df[columnas_texto].head())

"""### 14. Codificación de variables categóricas gerarquicas

#### 14.1. Turno (Mañana, Tarde, Noche) -> (1, 2 ,3)
"""

orden_turno = {'Mañana': 1, 'Tarde': 2, 'Noche': 3}
df['turno_cod'] = df['turno'].map(orden_turno)

print(df[['turno', 'turno_cod']].head(10))

df.drop(columns='turno', inplace=True)

print("\nColumnas actuales:", df.columns.tolist())

"""#### 14.2. Día (Lunes, Martes, Miercoles, Jueves, Viernes, Sabado, Domingo) -> (0, 1, 2, 3, 4, 5, 6)"""

df['nombre_dia_en'] = pd.to_datetime(df['fecha']).dt.day_name()

dias_traducidos = {
    'Monday': 'Lunes',
    'Tuesday': 'Martes',
    'Wednesday': 'Miércoles',
    'Thursday': 'Jueves',
    'Friday': 'Viernes',
    'Saturday': 'Sábado',
    'Sunday': 'Domingo'
}
df['nombre_dia'] = df['nombre_dia_en'].map(dias_traducidos)

df['dia_semana_cod'] = pd.to_datetime(df['fecha']).dt.dayofweek

df.drop(columns=['nombre_dia_en'], inplace=True)

print(df[['nombre_dia', 'dia_semana_cod']].head(10))

df.drop(columns='nombre_dia', inplace=True)

print("\nColumnas actuales:", df.columns.tolist())

"""### 15. Codificación de variables categóricas no gerarquicas

#### 15.1. Codificar zona
"""

from sklearn.preprocessing import LabelEncoder
le_zona = LabelEncoder()
df['zona_cod'] = le_zona.fit_transform(df['zona'])
mapa_zona = dict(enumerate(le_zona.classes_))
mapa_zona_inverso = {v: k for k, v in mapa_zona.items()}

# Verificamos parte del diccionario
print("Ejemplo mapa zona:")
for k in list(mapa_zona.items())[:5]:
    print(k)

"""#### 15.2. Codificar sector"""

le_sector = LabelEncoder()
df['sector_cod'] = le_sector.fit_transform(df['sector'])
mapa_sector = dict(enumerate(le_sector.classes_))
mapa_sector_inverso = {v: k for k, v in mapa_sector.items()}

# Verificamos parte del diccionario
print("Ejemplo mapa sector:")
for k in list(mapa_sector.items())[:5]:
    print(k)

"""#### Generar el mapa sector → zona"""

# Crear mapa: sector → zona
sector_a_zona = df[['sector', 'zona']].drop_duplicates().set_index('sector')['zona'].to_dict()


# Verificamos parte del diccionario
print("zona -> sector")
for k in list(sector_a_zona.items())[:5]:
    print(k)

"""#### 15.3. Codificar tipo de ocurrencia"""

le_tipo = LabelEncoder()
df['tipo_ocurrencia_cod'] = le_tipo.fit_transform(df['tipo_ocurrencia'])
mapa_tipo_ocurrencia = dict(enumerate(le_tipo.classes_))
mapa_tipo_ocurrencia_inverso = {v: k for k, v in mapa_tipo_ocurrencia.items()}

# Verificamos parte del diccionario
print("Ejemplo mapa tipo_ocurrencia:")
for k in list(mapa_tipo_ocurrencia.items())[:5]:
    print(k)

df.drop(columns=['zona', 'sector', 'tipo_ocurrencia'], inplace=True)

"""### 16. División de la fecha en año, mes, día"""

df['año'] = df['fecha'].dt.year
df['mes'] = df['fecha'].dt.month
df['día'] = df['fecha'].dt.day

print("DataFrame con las columnas 'año', 'mes' y 'día':")
print(df[['año', 'mes', 'día']].head())

df.drop(columns='fecha', inplace=True)

"""### 17. Convertir al formato correcto"""

# Verificación final
print("-> Tipos de datos actualizados:")
print(df.dtypes)

"""## Ingeniería de características

### 18. Calificar por fin de semana
"""

df['es_fin_semana'] = df['dia_semana_cod'].isin([5, 6]).astype(int)

print(df[['dia_semana_cod', 'es_fin_semana']].head(10))

df

"""## Planificación para modelado

### 20. Partición del dataset

Para modelo de Clasificación
"""

# Variables seleccionadas para clasificación
df_clasificacion = df[[
    'año', 'mes', 'día',
    'dia_semana_cod',
    'turno_cod',
    'sector_cod',
    'es_fin_semana',
    'tipo_ocurrencia_cod'  # target
]].copy()

# División 80/20
total_filas = len(df_clasificacion)
entrenamiento = int(0.8 * total_filas)
prueba = total_filas - entrenamiento

df_clas_train = df_clasificacion.iloc[:entrenamiento].copy()
df_clas_test = df_clasificacion.iloc[entrenamiento:].copy()

print("-> Conjunto de clasificación:")
print("\nVariables utilizadas:", df_clasificacion.columns.tolist(), "\n")
print(f"Entrenamiento (80%): {df_clas_train.shape[0]} filas")
print(f"Prueba (20%):        {df_clas_test.shape[0]} filas")

"""Para modelo de regresión"""

# Variables seleccionadas para regresión
df_regresion = df[[
    'año', 'mes', 'día',
    'dia_semana_cod',
    'turno_cod',
    'sector_cod',
    'tipo_ocurrencia_cod',  # input
    'registro_atipico',
    'es_fin_semana',
    'chofer', 'caminante', 'motorizado'  # targets
]].copy()

# División 80/20
total_filas = len(df_regresion)
entrenamiento = int(0.8 * total_filas)
prueba = total_filas - entrenamiento

df_reg_train = df_regresion.iloc[:entrenamiento].copy()
df_reg_test = df_regresion.iloc[entrenamiento:].copy()

print("-> Conjunto de regresión:")
print("\nVariables utilizadas:", df_regresion.columns.tolist(), "\n")
print(f"Entrenamiento (80%): {df_reg_train.shape[0]} filas")
print(f"Prueba (20%):        {df_reg_test.shape[0]} filas")

"""# Agrupamiento de clases"""

# 1. Cantidad total de filas antes del filtrado
total_original = len(df)
print(f"Total de registros antes del filtrado: {total_original}")

# 2. Recuperar el nombre original del tipo de ocurrencia
df['tipo_ocurrencia_nombre'] = df['tipo_ocurrencia_cod'].map(mapa_tipo_ocurrencia)

# 3. Contar registros del tipo 'Otros'
otros_count = df[df['tipo_ocurrencia_nombre'] == 'Otros'].shape[0]
print(f"Cantidad de registros con tipo 'Otros': {otros_count}")

# 4. Eliminar registros con tipo 'Otros'
df_filtrado = df[df['tipo_ocurrencia_nombre'] != 'Otros'].copy()
print(f"Registros después de eliminar 'Otros': {len(df_filtrado)}")

# 5. Contar ocurrencias de cada clase
conteo_ocurrencias = df_filtrado['tipo_ocurrencia_nombre'].value_counts()

# 6. Detectar clases con menos de 5 registros
clases_raras = conteo_ocurrencias[conteo_ocurrencias < 5].index.tolist()
print(f"Clases con menos de 5 registros: {len(clases_raras)}")

# 7. Eliminar registros de esas clases
df_final = df_filtrado[~df_filtrado['tipo_ocurrencia_nombre'].isin(clases_raras)].copy()
print(f"Total de registros después de eliminar clases con <5 registros: {len(df_final)}")

# Agrupar por tipo de ocurrencia y contar
conteo_clases = (
    df_final.groupby(['tipo_ocurrencia_cod', 'tipo_ocurrencia_nombre'])
    .size()
    .reset_index(name='cantidad')
    .sort_values(by='cantidad', ascending=False)
)

# Guardar a CSV
conteo_clases.to_csv('conteo_clases_incidentes.csv', index=False, encoding='utf-8-sig')

# Descargar csv
#from google.colab import files
#files.download('conteo_clases_incidentes.csv')

def asignar_grupo(nombre):
    nombre_lower = nombre.lower()

    # Reglas generales
    if any(x in nombre_lower for x in ['agresión', 'agresion', 'violencia', 'golpe', 'gresca']):
        return 'Violencia'
    elif any(x in nombre_lower for x in ['robo', 'hurto', 'estafa', 'asalto']):
        return 'Robos'
    elif any(x in nombre_lower for x in ['licor', 'alcohólica', 'psicotrópicas', 'sustancia', 'marihuana']):
        return 'Consumo de sustancias'
    elif any(x in nombre_lower for x in ['apoyo', 'asistencia', 'samu', 'auxilio', 'herida', 'doctor', 'coordinacion']):
        return 'Apoyo y asistencia'
    elif any(x in nombre_lower for x in ['sospechosa', 'sospechoso', 'sujeto', 'delincuente', 'detenido', 'intervenido', 'bitroquero', 'patrullaje']):
        return 'Seguridad ciudadana'
    elif any(x in nombre_lower for x in ['choque', 'tráns', 'vehículo', 'vehiculos', 'tránsito', 'congestion', 'atropello', 'mal estacionada', 'mal estacionado']):
        return 'Tránsito'
    elif any(x in nombre_lower for x in ['perro', 'can', 'animal', 'mordedura', 'fauna']):
        return 'Animales'
    elif any(x in nombre_lower for x in ['basura', 'desmonte', 'fuga', 'gas', 'agua', 'toldo', 'lavadero', 'verde', 'forado']):
        return 'Ambiente y limpieza'
    elif any(x in nombre_lower for x in ['ruido', 'musica', 'pirotecnicos']):
        return 'Escándalo público'
    elif any(x in nombre_lower for x in ['incendio', 'suicidio', 'amenazas', 'muerto', 'riesgo', 'caido', 'fuego', 'occiso', 'balacera']):
        return 'Emergencias'
    elif any(x in nombre_lower for x in ['miccionan', 'acoso', 'meretrices', 'homosexuales', 'obsceno']):
        return 'Actos Obsenos'
    elif any(x in nombre_lower for x in ['obstruyendo', 'material de construccion', 'retiro ambulantes', 'orate']):
        return 'Obstrucción vía pública'
    elif any(x in nombre_lower for x in ['escolares', 'alumnos', 'abandono escolar']):
        return 'Incidentes escolares'
    elif any(x in nombre_lower for x in ['escándalo', 'cómicos ambulantes', 'barristas']):
        return 'Alteración del orden en vía pública'
    else:
        return nombre

# Contar clases
conteo_clases['tipo_grupo_nombre'] = conteo_clases['tipo_ocurrencia_nombre'].apply(asignar_grupo)

# Recuento actualizado
conteo_clases['tipo_grupo_nombre'].nunique()
conteo_clases['tipo_grupo_nombre'].value_counts()

# Total de clases únicas después del filtrado
total_clases_originales = df_final['tipo_ocurrencia_nombre'].nunique()
print(f"Total de clases originales (filtradas): {total_clases_originales}")

# Total de entradas en la tabla de conteo
total_filas_conteo = conteo_clases.shape[0]
print(f"Total de clases en la tabla 'conteo_clases': {total_filas_conteo}")

# Verificar si coinciden
if total_clases_originales == total_filas_conteo:
    print("-> Todas las clases están representadas en la tabla de agrupamiento.")
else:
    print("-> Hay una discrepancia entre el DataFrame filtrado y la tabla de agrupación.")

df_final

# Aplicar la función al nombre de ocurrencia para asignar el grupo
df_final['grupo_incidente'] = df_final['tipo_ocurrencia_nombre'].apply(asignar_grupo)

# Verificamos los primeros registros
print(df_final[['tipo_ocurrencia_nombre', 'grupo_incidente']].head())

df_final

from sklearn.preprocessing import LabelEncoder

# Inicializamos el codificador
le_grupo = LabelEncoder()

# Codificamos los grupos
df_final['grupo_incidente_cod'] = le_grupo.fit_transform(df_final['grupo_incidente'])

# Creamos el diccionario de codificación
grupo_dict = dict(zip(le_grupo.classes_, le_grupo.transform(le_grupo.classes_)))
grupo_dict_inv = {v: k for k, v in grupo_dict.items()}  # para decodificar

# Mostramos ejemplo del mapeo
print("Diccionario de codificación:")
for k, v in grupo_dict.items():
    print(f"{k} → {v}")

"""Creamos diccionario de grupo_incidente_cod  --> grupo_incidente"""

mapa_grupo_incidente = dict(zip(df_final['grupo_incidente_cod'], df_final['grupo_incidente']))

df_final

"""# MODELOS Clasificacion"""

# Features
X = df_final[[
    'año', 'mes', 'día',
    'dia_semana_cod', 'es_fin_semana',
    'turno_cod', 'sector_cod', 'zona_cod'
]]

# Nuevo target: el grupo
y = df_final['grupo_incidente_cod']

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Entrenamiento: {X_train.shape[0]} filas")
print(f"Validación: {X_val.shape[0]} filas")

"""### Modelo 1: Random Forest

#### Modelo 1.1: Random Forest base
"""

import os

# Crear carpeta de modelos
os.makedirs("modelos", exist_ok=True)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# 1. Entrenamiento del modelo
modelo_rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

modelo_rf.fit(X_train, y_train)

# 2. Predicción
y_proba = modelo_rf.predict_proba(X_val)

# 3. Métricas top-5
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar métricas
print("-> Random Forest (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_rf = {
    'Modelo': 'Random Forest',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo
joblib.dump(modelo_rf, 'modelos/modelo_rf.pkl')
print("-> Modelo Random Forest guardado en 'modelos/modelo_rf.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_rf.feature_importances_
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='steelblue', orient='h')
plt.title('Importancia de características - Random Forest')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Buscando los mejores hiperparametros"""

# from sklearn.model_selection import RandomizedSearchCV
# from sklearn.ensemble import RandomForestClassifier

# # Modelo base
# rf = RandomForestClassifier(random_state=42)

# # Espacio de búsqueda razonable
# param_dist = {
#     'n_estimators': [50, 100, 200, 300, 500],
#     'max_depth': [None, 10, 20, 30, 50],
#     'min_samples_split': [2, 5, 10],
#     'min_samples_leaf': [1, 2, 4],
#     'max_features': ['sqrt', 'log2']
# }

# # Búsqueda aleatoria con validación cruzada
# search = RandomizedSearchCV(
#     rf,
#     param_distributions=param_dist,
#     n_iter=30,
#     cv=3,
#     scoring='accuracy',
#     n_jobs=-1,
#     random_state=42,
#     verbose=1
# )

# search.fit(X_train, y_train)

# # Mostrar mejores parámetros
# print("Mejores hiperparámetros encontrados:")
# print(search.best_params_)

# Mostrar mejores parámetros
print("Mejores hiperparámetros encontrados:")
print("{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 10}")

"""#### Modelo 1.2: RandomForest con los mejores hiperparametros"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# 1. Entrenamiento del modelo optimizado
modelo_rf_optimo = RandomForestClassifier(
    n_estimators=200,
    min_samples_split=5,
    min_samples_leaf=2,
    max_features='log2',
    max_depth=10,
    random_state=42,
    n_jobs=-1
)

modelo_rf_optimo.fit(X_train, y_train)

# 2. Predicción
y_proba = modelo_rf_optimo.predict_proba(X_val)

# 3. Métricas top-5
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar métricas
print("-> Random Forest Óptimo (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_rf_optimo = {
    'Modelo': 'Random Forest Óptimo',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo
joblib.dump(modelo_rf_optimo, 'modelos/modelo_rf_optimo.pkl')
print("-> Modelo Random Forest Óptimo guardado en 'modelos/modelo_rf_optimo.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_rf_optimo.feature_importances_
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='seagreen', orient='h')
plt.title('Importancia de características - Random Forest Óptimo')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Comparativa de modelo base vs modelo con mejores hiperparametros:"""

import pandas as pd

# Unir métricas
resultados_rf = [metrics_rf, metrics_rf_optimo]

# Crear DataFrame
df_comparativa_rf = pd.DataFrame(resultados_rf)

# Reordenar columnas
df_comparativa_rf = df_comparativa_rf[['Modelo', 'Top-5 Accuracy', 'Top-5 Loss']]

# Redondear a 4 decimales
df_comparativa_rf.iloc[:, 1:] = df_comparativa_rf.iloc[:, 1:].round(4)

# Mostrar con 4 decimales
pd.options.display.float_format = '{:.4f}'.format
print("-> Comparativa de Random Forest: Base vs Óptimo")
display(df_comparativa_rf)

# Reset formato
pd.reset_option("display.float_format")

"""### Modelo 2: Lightgbm

#### Modelo 2.1: Lightgbm base
"""

!pip install lightgbm

from lightgbm import LGBMClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import pandas as pd

# 1. Entrenamiento del modelo base
modelo_lgbm = LGBMClassifier(
    objective='multiclass',
    num_class=y.nunique(),
    n_estimators=100,
    random_state=42
)
modelo_lgbm.fit(X_train, y_train)

# 2. Predicción
y_proba = modelo_lgbm.predict_proba(X_val)

# 3. Métricas Top-5
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar métricas
print("-> LightGBM (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_lgbm = {
    'Modelo': 'LightGBM',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo
joblib.dump(modelo_lgbm, 'modelos/modelo_lgbm.pkl')
print("-> Modelo LightGBM guardado en 'modelos/modelo_lgbm.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_lgbm.feature_importances_
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='steelblue', orient='h')
plt.title('Importancia de características - LightGBM')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Buscando los mejores hiperparametros"""

# from sklearn.model_selection import RandomizedSearchCV

# # Espacio de búsqueda para LightGBM
# param_dist_lgbm = {
#     'n_estimators': [100, 200, 300],
#     'learning_rate': [0.05, 0.1, 0.2],
#     'max_depth': [-1, 5, 10, 20],
#     'num_leaves': [31, 50, 100],
#     'min_child_samples': [10, 20, 30],
#     'subsample': [0.6, 0.8, 1.0],
#     'colsample_bytree': [0.6, 0.8, 1.0]
# }

# # RandomizedSearchCV
# lgbm_random = RandomizedSearchCV(
#     estimator=LGBMClassifier(objective='multiclass', num_class=y.nunique(), random_state=42),
#     param_distributions=param_dist_lgbm,
#     n_iter=30,
#     scoring='accuracy',
#     cv=3,
#     verbose=1,
#     random_state=42,
#     n_jobs=-1
# )

# lgbm_random.fit(X_train, y_train)

# print("\nMejores hiperparámetros encontrados para LightGBM:")
# print(lgbm_random.best_params_)

# Mostrar mejores hiperparámetros
print("Mejores hiperparámetros encontrados para LightGBM:")
print("{'subsample': 0.6, 'num_leaves': 50, 'n_estimators': 100, 'min_child_samples': 30, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 1.0}")

"""#### Modelo 2.2: Lightgbm con los mejores hiperparametros"""

from lightgbm import LGBMClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# 1. Entrenar modelo optimizado con mejores hiperparámetros
modelo_lgbm_optimo = LGBMClassifier(
    objective='multiclass',
    num_class=y.nunique(),
    n_estimators=100,
    learning_rate=0.05,
    max_depth=10,
    num_leaves=50,
    min_child_samples=30,
    subsample=0.6,
    colsample_bytree=1.0,
    random_state=42
)

modelo_lgbm_optimo.fit(X_train, y_train)

# 2. Predicción
y_proba = modelo_lgbm_optimo.predict_proba(X_val)

# 3. Métricas top-5
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar métricas
print("-> LightGBM Optimizado (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para comparativa
metrics_lgbm_opt = {
    'Modelo': 'LightGBM Optimizado',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo entrenado
joblib.dump(modelo_lgbm_optimo, 'modelos/modelo_lgbm_optimo.pkl')
print("-> Modelo LightGBM optimizado guardado en 'modelos/modelo_lgbm_optimo.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_lgbm_optimo.feature_importances_
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='seagreen', orient='h')
plt.title('Importancia de características - LightGBM Optimizado')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Comparativa de modelo base vs modelo con mejores hiperparametros:"""

import pandas as pd

# Unir métricas
resultados_lgbm = [metrics_lgbm, metrics_lgbm_opt]

# Crear DataFrame
df_comparativa_lgbm = pd.DataFrame(resultados_lgbm)

# Reordenar columnas
df_comparativa_lgbm = df_comparativa_lgbm[['Modelo', 'Top-5 Accuracy', 'Top-5 Loss']]

# Redondear a 4 decimales
df_comparativa_lgbm.iloc[:, 1:] = df_comparativa_lgbm.iloc[:, 1:].round(4)

# Mostrar con 4 decimales
pd.options.display.float_format = '{:.4f}'.format
print("-> Comparativa de LightGBM: Base vs Óptimo")
display(df_comparativa_lgbm)

# Reset formato
pd.reset_option("display.float_format")

"""### Modelo 3: XGBoost

#### Modelo 3.1: XGBoost base
"""

!pip install xgboost

from xgboost import XGBClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import joblib

# 1. Crear y entrenar el modelo
modelo_xgb = XGBClassifier(
    objective='multi:softprob',
    num_class=y.nunique(),
    eval_metric='mlogloss',
    n_estimators=100,
    random_state=42
)
modelo_xgb.fit(X_train, y_train)

# 2. Predicciones
y_proba = modelo_xgb.predict_proba(X_val)

# 3. Métricas
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar métricas
print("-> XGBoost (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_xgb = {
    'Modelo': 'XGBoost',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Gráfico de importancia de características
importances = modelo_xgb.feature_importances_
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='steelblue', orient='h')
plt.title('Importancia de características - XGBoost')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

# 7. Guardar el modelo entrenado
joblib.dump(modelo_xgb, 'modelos/modelo_xgb.pkl')
print("-> Modelo XGBoost guardado en 'modelos/modelo_xgb.pkl'\n")

"""#### Buscando los mejores hiperparametros"""

# from sklearn.model_selection import RandomizedSearchCV
# from xgboost import XGBClassifier

# # Definir espacio de búsqueda
# param_dist = {
#     'n_estimators': [50, 100, 200, 300],
#     'max_depth': [3, 5, 10, 20],
#     'learning_rate': [0.01, 0.05, 0.1, 0.2],
#     'subsample': [0.6, 0.8, 1.0],
#     'colsample_bytree': [0.6, 0.8, 1.0],
#     'gamma': [0, 1, 5],
#     'min_child_weight': [1, 5, 10]
# }

# # Instanciar modelo base
# xgb_base = XGBClassifier(
#     objective='multi:softprob',
#     num_class=y.nunique(),
#     eval_metric='mlogloss',
#     use_label_encoder=False,
#     random_state=42
# )

# # Randomized search con validación cruzada
# search_xgb = RandomizedSearchCV(
#     xgb_base,
#     param_distributions=param_dist,
#     n_iter=30,
#     scoring='accuracy',
#     cv=3,
#     n_jobs=-1,
#     verbose=1,
#     random_state=42
# )

# search_xgb.fit(X_train, y_train)

# # Mostrar mejores hiperparámetros
# print("Mejores hiperparámetros encontrados para XGBoost:")
# print(search_xgb.best_params_)

# Mostrar mejores hiperparámetros
print("Mejores hiperparámetros encontrados para XGBoost:")
print("{'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 10, 'max_depth': 20, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 0.8}")

"""#### Modelo 3.2: XGboost con los mejores hiperparametros"""

from xgboost import XGBClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import joblib

# 1. Crear y entrenar el modelo optimizado
modelo_xgb_optimo = XGBClassifier(
    objective='multi:softprob',
    num_class=y.nunique(),
    eval_metric='mlogloss',
    subsample=0.8,
    n_estimators=300,
    min_child_weight=10,
    max_depth=20,
    learning_rate=0.1,
    gamma=1,
    colsample_bytree=0.8,
    random_state=42
)
modelo_xgb_optimo.fit(X_train, y_train)

# 2. Predicciones
y_proba = modelo_xgb_optimo.predict_proba(X_val)

# 3. Métricas
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar resultados
print("-> CatBoost Óptimo (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_ctb_opt = {
    'Modelo': 'CatBoost Óptimo',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo
joblib.dump(modelo_ctb_optimo, 'modelos/modelo_ctb_optimo.pkl')
print("-> Modelo CatBoost Óptimo guardado como 'modelos/modelo_ctb_optimo.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_ctb_optimo.get_feature_importance()
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='seagreen', orient='h')
plt.title('Importancia de características - CatBoost Óptimo')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Comparativa de modelo base vs modelo con mejores hiperparametros:"""

import pandas as pd

# Unir métricas
resultados_xgb = [metrics_xgb, metrics_xgb_opt]

# Crear DataFrame
df_comparativa_xgb = pd.DataFrame(resultados_xgb)

# Reordenar columnas
df_comparativa_xgb = df_comparativa_xgb[['Modelo', 'Top-5 Accuracy', 'Top-5 Loss']]

# Redondear a 4 decimales
df_comparativa_xgb.iloc[:, 1:] = df_comparativa_xgb.iloc[:, 1:].round(4)

# Mostrar con 4 decimales
pd.options.display.float_format = '{:.4f}'.format
print("-> Comparativa de XGBoost: Base vs Óptimo")
display(df_comparativa_xgb)

# Reset formato
pd.reset_option("display.float_format")

"""### Modelo 4: CatBoost

#### Modelo 4.1: CatBoost base
"""

!pip install catboost --quiet

from catboost import CatBoostClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import joblib

# 1. Crear y entrenar el modelo base
modelo_ctb = CatBoostClassifier(
    iterations=100,
    learning_rate=0.1,
    loss_function='MultiClass',
    random_seed=42,
    verbose=0
)
modelo_ctb.fit(X_train, y_train)

# 2. Predicciones
y_proba = modelo_ctb.predict_proba(X_val)

# 3. Métricas
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar resultados
print("-> CatBoost (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_ctb = {
    'Modelo': 'CatBoost',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo
joblib.dump(modelo_ctb, 'modelos/modelo_ctb.pkl')
print("-> Modelo CatBoost guardado como 'modelos/modelo_ctb.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_ctb.get_feature_importance()
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='steelblue', orient='h')
plt.title('Importancia de características - CatBoost')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Buscando los mejores hiperparametros"""

# from sklearn.model_selection import RandomizedSearchCV
# from catboost import CatBoostClassifier

# # Espacio de búsqueda
# param_dist = {
#     'iterations': [100, 200, 300],
#     'learning_rate': [0.01, 0.05, 0.1],
#     'depth': [6, 8, 10],
#     'l2_leaf_reg': [1, 3, 5, 7],
#     'border_count': [32, 64, 128]
# }

# # Modelo base
# cat = CatBoostClassifier(loss_function='MultiClass', verbose=0, random_state=42)

# # Búsqueda aleatoria con validación cruzada
# search_cat = RandomizedSearchCV(
#     estimator=cat,
#     param_distributions=param_dist,
#     n_iter=30,
#     scoring='accuracy',
#     cv=3,
#     verbose=1,
#     n_jobs=-1,
#     random_state=42
# )

# # Entrenar
# search_cat.fit(X_train, y_train)

# # Mostrar mejores parámetros
# print("Mejores hiperparámetros encontrados para CatBoost:")
# print(search_cat.best_params_)

# Mostrar mejores parámetros
print("Mejores hiperparámetros encontrados para CatBoost:")
print("{'learning_rate': 0.05, 'l2_leaf_reg': 1, 'iterations': 300, 'depth': 6, 'border_count': 32}")

"""#### Modelo 4.2: Catboost con los mejores hiperparametros"""

from catboost import CatBoostClassifier
from sklearn.metrics import top_k_accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import joblib

# 1. Crear y entrenar el modelo optimizado
modelo_ctb_optimo = CatBoostClassifier(
    iterations=300,
    learning_rate=0.05,
    depth=6,
    l2_leaf_reg=1,
    border_count=32,
    loss_function='MultiClass',
    random_seed=42,
    verbose=0
)
modelo_ctb_optimo.fit(X_train, y_train)

# 2. Predicciones
y_proba = modelo_ctb_optimo.predict_proba(X_val)

# 3. Métricas
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# 4. Mostrar resultados
print("-> CatBoost Óptimo (Grupos):")
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}\n")

# 5. Guardar métricas para tabla comparativa
metrics_ctb_opt = {
    'Modelo': 'CatBoost Óptimo',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss
}

# 6. Guardar modelo
joblib.dump(modelo_ctb_optimo, 'modelos/modelo_ctb_optimo.pkl')
print("-> Modelo CatBoost Óptimo guardado como 'modelos/modelo_ctb_optimo.pkl'\n")

# 7. Gráfico de importancia de características
importances = modelo_ctb_optimo.get_feature_importance()
features = X_train.columns

plt.figure(figsize=(8, 4))
sns.barplot(x=importances, y=features, color='seagreen', orient='h')
plt.title('Importancia de características - CatBoost Óptimo')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""#### Comparativa de modelo base vs modelo con mejores hiperparametros:"""

import pandas as pd

# Unir métricas
resultados_ctb = [metrics_ctb, metrics_ctb_opt]

# Crear DataFrame
df_comparativa_ctb = pd.DataFrame(resultados_ctb)

# Reordenar columnas necesarias
columnas = ['Modelo', 'Top-5 Accuracy', 'Top-5 Loss']
df_comparativa_ctb = df_comparativa_ctb[columnas]

# Redondear resultados a 4 decimales
df_comparativa_ctb.iloc[:, 1:] = df_comparativa_ctb.iloc[:, 1:].round(4)

# Mostrar tabla comparativa
print("\n-> Comparativa de CatBoost: Base vs Óptimo")
display(df_comparativa_ctb)

# Reset formato
pd.reset_option("display.float_format")

"""#### Modelo 4.3: catboost con metricas adicionales"""

from sklearn.metrics import top_k_accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import label_binarize
import numpy as np
import joblib

# Cargar modelo
modelo_ctb = joblib.load('modelos/modelo_ctb.pkl')

# Predicciones de probabilidad
y_proba = modelo_ctb.predict_proba(X_val)

# Top-5 Accuracy y Top-5 Loss
top5_acc = top_k_accuracy_score(y_val, y_proba, k=5)
top5_loss = 1 - top5_acc

# Predicciones top-5
top5_preds = np.argsort(y_proba, axis=1)[:, -5:]
y_true_expanded = np.repeat(y_val.values.reshape(-1, 1), 5, axis=1)
top5_hits = (top5_preds == y_true_expanded).astype(int)

# Top-5 Precision
top5_precision = top5_hits.sum(axis=1).mean() / 5

# Top-5 Recall
top5_recall = top5_hits.sum(axis=1).mean()

# Top-5 F1-score
if top5_precision + top5_recall > 0:
    top5_f1 = 2 * (top5_precision * top5_recall) / (top5_precision + top5_recall)
else:
    top5_f1 = 0.0

# Top-5 AUC
y_true_bin = label_binarize(y_val, classes=np.unique(y_val))
top5_auc = roc_auc_score(y_true_bin, y_proba, multi_class='ovr')

# Mostrar resultados
print(f"Top-5 Accuracy: {top5_acc:.4f}")
print(f"Top-5 Loss: {top5_loss:.4f}")
print(f"Top-5 Precision: {top5_precision:.4f}")
print(f"Top-5 Recall: {top5_recall:.4f}")
print(f"Top-5 F1-score: {top5_f1:.4f}")
print(f"Top-5 AUC: {top5_auc:.4f}")

# Guardar resultados
metrics_ctb_all = {
    'Modelo': 'CatBoost Óptimo',
    'Top-5 Accuracy': top5_acc,
    'Top-5 Loss': top5_loss,
    'Top-5 Precision': top5_precision,
    'Top-5 Recall': top5_recall,
    'Top-5 F1-score': top5_f1,
    'Top-5 AUC': top5_auc
}

"""### Modelo 5: Red Neuronal Multiclase

#### Modelo 5.1: Red Neuronal base
"""

!pip install tensorflow

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# 1. Preparar variables
categorical_cols = ['turno_cod', 'sector_cod', 'zona_cod', 'dia_semana_cod']
numeric_cols = ['año', 'mes', 'día', 'es_fin_semana']
target_col = 'grupo_incidente_cod'

X_cat = df_final[categorical_cols].astype('int32')
X_num = df_final[numeric_cols].astype('float32')
y = df_final[target_col]

# 2. Train/test split
X_cat_train, X_cat_val, X_num_train, X_num_val, y_train, y_val = train_test_split(
    X_cat, X_num, y, test_size=0.2, random_state=42, stratify=y
)

# 3. One-hot encoding del target
y_train_cat = to_categorical(y_train)
y_val_cat = to_categorical(y_val)
num_classes = y_train_cat.shape[1]

# 4. Modelo funcional con embeddings
inputs_cat = []
embeddings = []

for col in categorical_cols:
    input_cat = Input(shape=(1,), name=f'{col}_input')
    vocab_size = int(df_final[col].nunique()) + 1
    embed_dim = int(min(50, vocab_size + 1) // 2)
    embed = Embedding(input_dim=vocab_size, output_dim=embed_dim)(input_cat)
    embed = Flatten()(embed)
    inputs_cat.append(input_cat)
    embeddings.append(embed)

input_num = Input(shape=(len(numeric_cols),), name='numerical_input')
normalized = BatchNormalization()(input_num)

x = Concatenate()(embeddings + [normalized])
x = Dense(128, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x = Dense(64, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x = Dense(32, activation='relu')(x)
x = BatchNormalization()(x)
output = Dense(num_classes, activation='softmax')(x)

modelo_nn = Model(inputs=inputs_cat + [input_num], outputs=output)

# 5. Compilar
modelo_nn.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')]
)

# 6. EarlyStopping
callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# 7. Entrenamiento
history = modelo_nn.fit(
    x=[X_cat_train[col] for col in categorical_cols] + [X_num_train],
    y=y_train_cat,
    validation_data=([X_cat_val[col] for col in categorical_cols] + [X_num_val], y_val_cat),
    epochs=50,
    batch_size=64,
    callbacks=[callback],
    verbose=1
)

# 8. Agregar top-5 loss y val top-5 loss al historial
history.history['top_5_loss'] = [1 - acc for acc in history.history['top_5_accuracy']]
history.history['val_top_5_loss'] = [1 - acc for acc in history.history['val_top_5_accuracy']]

# 1. Mostrar métricas finales
val_top5_acc = history.history['val_top_5_accuracy'][-1]
val_top5_loss = 1 - val_top5_acc
train_top5_acc = history.history['top_5_accuracy'][-1]
train_top5_loss = 1 - train_top5_acc

print("-> Red Neuronal Básica (Grupos):")
print(f"Top-5 Accuracy (train): {train_top5_acc:.4f}")
print(f"Top-5 Loss (train):     {train_top5_loss:.4f}")
print(f"Top-5 Accuracy (val):   {val_top5_acc:.4f}")
print(f"Top-5 Loss (val):       {val_top5_loss:.4f}")

# 2. Guardar métricas para comparativa
metrics_nn = {
    'Modelo': 'Red Neuronal Básica',
    'Top-5 Accuracy (Train)': train_top5_acc,
    'Top-5 Loss (Train)': train_top5_loss,
    'Top-5 Accuracy (Val)': val_top5_acc,
    'Top-5 Loss (Val)': val_top5_loss
}

# 3. Guardar modelo
import os
os.makedirs("modelos", exist_ok=True)
modelo_nn.save("modelos/modelo_nn.keras")
print("\n-> Modelo guardado como 'modelos/modelo_nn.keras'\n")

# 4. Gráfico de Top-5 Accuracy y Top-5 Loss
import matplotlib.pyplot as plt

epochs = range(1, len(history.history['top_5_accuracy']) + 1)

plt.figure(figsize=(14, 5))

# Top-5 Accuracy
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['top_5_accuracy'], label='Train', marker='o')
plt.plot(epochs, history.history['val_top_5_accuracy'], label='Val', marker='o')
plt.title('Top-5 Accuracy por época')
plt.xlabel('Época')
plt.ylabel('Top-5 Accuracy')
plt.legend()
plt.grid(True)

# Top-5 Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['top_5_loss'], label='Train', marker='o')
plt.plot(epochs, history.history['val_top_5_loss'], label='Val', marker='o')
plt.title('Top-5 Loss por época')
plt.xlabel('Época')
plt.ylabel('Top-5 Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""#### Modelo 5.2: Red Neuronal Optima"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.regularizers import l2
from tensorflow.keras.activations import swish
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# 1. Variables
categorical_cols = ['turno_cod', 'sector_cod', 'zona_cod', 'dia_semana_cod']
numeric_cols = ['año', 'mes', 'día', 'es_fin_semana']
target_col = 'grupo_incidente_cod'

X_cat = df_final[categorical_cols].astype('int32')
X_num = df_final[numeric_cols].astype('float32')
y = df_final[target_col]

X_cat_train, X_cat_val, X_num_train, X_num_val, y_train, y_val = train_test_split(
    X_cat, X_num, y, test_size=0.2, random_state=42, stratify=y
)

# 2. One-hot
y_train_cat = to_categorical(y_train)
y_val_cat = to_categorical(y_val)
num_classes = y_train_cat.shape[1]

# 3. Modelo funcional con embeddings
inputs_cat, embeddings = [], []
for col in categorical_cols:
    input_cat = Input(shape=(1,), name=f'{col}_input')
    vocab_size = int(df_final[col].nunique()) + 1
    embed_dim = int(min(50, vocab_size + 1) // 2)
    embed = Embedding(input_dim=vocab_size, output_dim=embed_dim)(input_cat)
    embed = Flatten()(embed)
    inputs_cat.append(input_cat)
    embeddings.append(embed)

input_num = Input(shape=(len(numeric_cols),), name='numerical_input')
normalized = BatchNormalization()(input_num)

x = Concatenate()(embeddings + [normalized])
x = Dense(256, activation=swish)(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x = Dense(128, activation=swish)(x)
x = BatchNormalization()(x)
x = Dropout(0.4)(x)
x = Dense(64, activation=swish)(x)
x = BatchNormalization()(x)
output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001))(x)

modelo_nn_optimo = Model(inputs=inputs_cat + [input_num], outputs=output)
modelo_nn_optimo.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')]
)

# 4. Entrenamiento
callback = EarlyStopping(monitor='val_top_5_accuracy', patience=12, min_delta=0.001, restore_best_weights=True)

history = modelo_nn_optimo.fit(
    x=[X_cat_train[col] for col in categorical_cols] + [X_num_train],
    y=y_train_cat,
    validation_data=([X_cat_val[col] for col in categorical_cols] + [X_num_val], y_val_cat),
    epochs=50,
    batch_size=64,
    callbacks=[callback],
    verbose=1
)

import matplotlib.pyplot as plt

# 5. Evaluación
val_top5_acc = history.history['val_top_5_accuracy'][-1]
val_top5_loss = 1 - val_top5_acc
train_top5_acc = history.history['top_5_accuracy'][-1]
train_top5_loss = 1 - train_top5_acc

print("-> Red Neuronal Óptima (Grupos):")
print(f"Top-5 Accuracy (entrenamiento): {train_top5_acc:.4f}")
print(f"Top-5 Loss (entrenamiento):     {train_top5_loss:.4f}")
print(f"Top-5 Accuracy (validación):    {val_top5_acc:.4f}")
print(f"Top-5 Loss (validación):        {val_top5_loss:.4f}")

# 6. Guardar métricas
metrics_nn_optimo = {
    'Modelo': 'Red Neuronal Óptima',
    'Top-5 Accuracy (Train)': train_top5_acc,
    'Top-5 Loss (Train)': train_top5_loss,
    'Top-5 Accuracy (Val)': val_top5_acc,
    'Top-5 Loss (Val)': val_top5_loss
}

# 7. Guardar modelo
modelo_nn_optimo.save("modelos/modelo_nn_optimo.keras")
print("\n-> Modelo guardado como 'modelos/modelo_nn_optimo.keras'")

# Calcular valores
epochs = list(range(1, len(history.history['top_5_accuracy']) + 1))
top_5_loss = [1 - acc for acc in history.history['top_5_accuracy']]
val_top_5_loss = [1 - acc for acc in history.history['val_top_5_accuracy']]

# Crear gráfico
plt.figure(figsize=(10, 4))

# Top-5 Accuracy
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['top_5_accuracy'], label='Train', marker='o')
plt.plot(epochs, history.history['val_top_5_accuracy'], label='Val', marker='o')
plt.title('Top-5 Accuracy por época')
plt.xlabel('Época')
plt.ylabel('Top-5 Accuracy')
plt.legend()
plt.grid(True)

# Top-5 Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, top_5_loss, label='Train', marker='o')
plt.plot(epochs, val_top_5_loss, label='Val', marker='o')
plt.title('Top-5 Loss por época')
plt.xlabel('Época')
plt.ylabel('Top-5 Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""#### Comparativa de modelo base vs modelo con mejores hiperparametros:"""

import pandas as pd

# Unir métricas
resultados_nn = [metrics_nn, metrics_nn_optimo]

# Crear DataFrame
df_comparativa_nn = pd.DataFrame(resultados_nn)

# Reordenar columnas necesarias
columnas = ['Modelo', 'Top-5 Accuracy (Train)', 'Top-5 Loss (Train)', 'Top-5 Accuracy (Val)', 'Top-5 Loss (Val)']
df_comparativa_nn = df_comparativa_nn[columnas]

# Redondear resultados a 4 decimales
df_comparativa_nn.iloc[:, 1:] = df_comparativa_nn.iloc[:, 1:].round(4)

# Mostrar tabla comparativa
print("\n-> Comparativa de red neuronal: Base vs Óptimo")
display(df_comparativa_nn)

# Reset formato
pd.reset_option("display.float_format")

"""#### Modelo 5.3: Red neuronal optima con metricas adicionales"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import label_binarize

# 1. Cargar modelo
modelo_nn_optimo = load_model("modelos/modelo_nn_optimo.keras")

# 2. Obtener probabilidades
y_proba = modelo_nn_optimo.predict([X_cat_val[col] for col in categorical_cols] + [X_num_val])
top5_preds = np.argsort(y_proba, axis=1)[:, -5:]

# 3. Expandir etiquetas reales
y_true_expanded = np.repeat(y_val.values.reshape(-1, 1), 5, axis=1)
top5_hits = (top5_preds == y_true_expanded).astype(int)

# 4. Top-5 Precision y Recall
top5_precision = top5_hits.sum(axis=1).mean() / 5
top5_recall = top5_hits.sum(axis=1).mean()

# 5. Top-5 F1-score
if top5_precision + top5_recall > 0:
    top5_f1 = 2 * (top5_precision * top5_recall) / (top5_precision + top5_recall)
else:
    top5_f1 = 0.0

# 6. Top-5 AUC
y_val_bin = label_binarize(y_val, classes=np.unique(y_val))
top5_auc = roc_auc_score(y_val_bin, y_proba, multi_class='ovr')

# 7. Top-5 Accuracy y Loss (val)
val_top5_acc = history.history['val_top_5_accuracy'][-1]
val_top5_loss = 1 - val_top5_acc

# 8. Top-5 Accuracy y Loss (train)
train_top5_acc = history.history['top_5_accuracy'][-1]
train_top5_loss = 1 - train_top5_acc

# 9. Mostrar todas las métricas
print("-> Métricas completas - Red Neuronal Óptima:")
print(f"Top-5 Accuracy (entrenamiento): {train_top5_acc:.4f}")
print(f"Top-5 Loss (entrenamiento):     {train_top5_loss:.4f}")
print(f"Top-5 Accuracy (validación):    {val_top5_acc:.4f}")
print(f"Top-5 Loss (validación):        {val_top5_loss:.4f}")
print(f"Top-5 Precision:                {top5_precision:.4f}")
print(f"Top-5 Recall:                   {top5_recall:.4f}")
print(f"Top-5 F1-score:                 {top5_f1:.4f}")
print(f"Top-5 AUC:                      {top5_auc:.4f}")


# Guardar resultados
metrics_nn_all = {
    'Modelo': 'Red Neuronal Óptima',
    'Top-5 Accuracy': val_top5_acc,
    'Top-5 Loss': val_top5_loss,
    'Top-5 Precision': top5_precision,
    'Top-5 Recall': top5_recall,
    'Top-5 F1-score': top5_f1,
    'Top-5 AUC': top5_auc
}

"""### Comparativa de todos los modelos (Accy y Loss)"""

import pandas as pd

# Lista consolidada de métricas (todas usan las claves 'Top-5 Accuracy' y 'Top-5 Loss')
resultados_val = [
    metrics_rf,
    metrics_rf_optimo,
    metrics_lgbm,
    metrics_lgbm_opt,
    metrics_xgb,
    metrics_xgb_opt,
    metrics_ctb,
    metrics_ctb_opt,
    {
        'Modelo': metrics_nn['Modelo'],
        'Top-5 Accuracy': metrics_nn['Top-5 Accuracy (Val)'],
        'Top-5 Loss': metrics_nn['Top-5 Loss (Val)']
    },
    {
        'Modelo': metrics_nn_optimo['Modelo'],
        'Top-5 Accuracy': metrics_nn_optimo['Top-5 Accuracy (Val)'],
        'Top-5 Loss': metrics_nn_optimo['Top-5 Loss (Val)']
    }
]

# Crear DataFrame
df_comparativa_final = pd.DataFrame(resultados_val)

# Redondear valores a 4 decimales
df_comparativa_final.iloc[:, 1:] = df_comparativa_final.iloc[:, 1:].round(4)

# Mostrar la tabla
print("\n-> Comparativa final de modelos (solo métricas de validación):")
display(df_comparativa_final)

# Reset formato
pd.reset_option("display.float_format")

"""### Comparativa de los modelos con todas las metricas"""

import pandas as pd

# Lista consolidada de métricas
resultados_all = [
    metrics_ctb_all,
    metrics_nn_all
]

# Crear DataFrame
df_modelos_all = pd.DataFrame([model_ctb_all, model_nn_all])

# Redondear métricas numéricas
df_modelos_all.iloc[:, 1:] = df_modelos_all.iloc[:, 1:].round(4)

# Mostrar
print("\n-> Comparativa extendida: CatBoost Óptimo vs Red Neuronal Óptima")
display(df_modelos_all)

# Reset formato (opcional)
pd.reset_option("display.float_format")

"""### Descargamos los modelos guardados"""

!zip -r modelos.zip modelos
from google.colab import files
files.download("modelos.zip")

"""### guardamos y descargamos todas las metricas"""

import pickle

# 1. Consolidar todas las métricas en un único diccionario
todas_las_metricas = {
    'metrics_rf': metrics_rf,
    'metrics_rf_optimo': metrics_rf_optimo,
    'metrics_lgbm': metrics_lgbm,
    'metrics_lgbm_opt': metrics_lgbm_opt,
    'metrics_xgb': metrics_xgb,
    'metrics_xgb_opt': metrics_xgb_opt,
    'metrics_ctb': metrics_ctb,
    'metrics_ctb_opt': metrics_ctb_opt,
    'metrics_nn': metrics_nn,
    'metrics_nn_optimo': metrics_nn_optimo,
    'metrics_ctb_all': metrics_ctb_all,
    'metrics_nn_all': metrics_nn_all
}

# 2. Guardar en archivo .pkl
with open('all_metrics.pkl', 'wb') as f:
    pickle.dump(todas_las_metricas, f)

print("-> Archivo 'todas_las_metricas.pkl' guardado exitosamente.")

from google.colab import files
files.download('all_metrics.pkl')

"""# Inputs para modelo Clasificacion"""

def transformar_input_real(año, mes, día, nombre_dia, turno, sector_nombre):
    # Codificar día de la semana
    dias_traducidos = {
        'Lunes': 0, 'Martes': 1, 'Miércoles': 2, 'Jueves': 3,
        'Viernes': 4, 'Sábado': 5, 'Domingo': 6
    }
    dia_semana_cod = dias_traducidos[nombre_dia]
    es_fin_semana = 1 if dia_semana_cod in [5, 6] else 0

    # Codificar turno
    orden_turno = {'Mañana': 1, 'Tarde': 2, 'Noche': 3}
    turno_cod = orden_turno[turno]

    # Codificar sector
    sector_cod = mapa_sector_inverso.get(sector_nombre, -1)

    # Buscar zona correspondiente al sector
    zona_nombre = sector_a_zona.get(sector_nombre)
    zona_cod = mapa_zona_inverso.get(zona_nombre, -1)

    # Retornar en formato que espera el modelo
    return {
        'año': año,
        'mes': mes,
        'día': día,
        'dia_semana_cod': dia_semana_cod,
        'es_fin_semana': es_fin_semana,
        'turno_cod': turno_cod,
        'sector_cod': sector_cod,
        'zona_cod': zona_cod
    }

entrada = transformar_input_real(
    año=2025,
    mes=6,
    día=14,
    nombre_dia='Viernes',
    turno='Tarde',
    sector_nombre='Sto.Dominguito'
)

print(entrada)

!pip install tensorflow

!pip install catboost --quiet

import os

# Crear carpeta de modelos
os.makedirs("modelos", exist_ok=True)

import joblib
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model

# Cargar modelos desde carpeta local
cat_model = joblib.load("modelos/modelo_ctb.pkl")
modelo_nn = load_model("modelos/modelo_nn_optimo.keras")

# 1. Transformar entrada real
entrada = transformar_input_real(
    año=2025,
    mes=6,
    día=14,
    nombre_dia='Viernes',
    turno='Tarde',
    sector_nombre='Sto.Dominguito'
)

print("Entrada transformada:")
print(entrada)

# Convertir a DataFrame para CatBoost
entrada_df = pd.DataFrame([entrada])

# 2. Top-5 con CATBOOST
probas_cat = cat_model.predict_proba(entrada_df)
top5_idx_cat = np.argsort(probas_cat[0])[::-1][:5]
top5_probs_cat = probas_cat[0][top5_idx_cat]
top5_grupos_cat = [mapa_grupo_incidente.get(i, f"Clase {i}") for i in top5_idx_cat]

print("\n-> Top-5 predicción con CatBoost:")
for i, (grupo, prob) in enumerate(zip(top5_grupos_cat, top5_probs_cat), 1):
    print(f"{i}. {grupo} ({prob*100:.2f}%)")

# preparar variables para la red
categorical_cols = ['turno_cod', 'sector_cod', 'zona_cod', 'dia_semana_cod']
numeric_cols = ['año', 'mes', 'día', 'es_fin_semana']
target_col = 'grupo_incidente_cod'

# 3. Top-5 con RED NEURONAL
entrada_cat = [np.array([entrada[col]]) for col in categorical_cols]
entrada_num = np.array([[entrada[col] for col in numeric_cols]])
probas_nn = modelo_nn.predict(entrada_cat + [entrada_num], verbose=0)

top5_idx_nn = np.argsort(probas_nn[0])[::-1][:5]
top5_probs_nn = probas_nn[0][top5_idx_nn]
top5_grupos_nn = [mapa_grupo_incidente.get(i, f"Clase {i}") for i in top5_idx_nn]

print("\n-> Top-5 predicción con Red Neuronal optima:")
for i, (grupo, prob) in enumerate(zip(top5_grupos_nn, top5_probs_nn), 1):
    print(f"{i}. {grupo} ({prob*100:.2f}%)")

# Obtener predicciones completas con la red neuronal óptima
entrada_cat = [np.array([entrada[col]]) for col in categorical_cols]
entrada_num = np.array([[entrada[col] for col in numeric_cols]])
probas_nn = modelo_nn.predict(entrada_cat + [entrada_num], verbose=0)[0]

# Crear DataFrame con nombre del grupo y su probabilidad
df_probs = pd.DataFrame({
    'Grupo': [mapa_grupo_incidente.get(i, f'Clase {i}') for i in range(len(probas_nn))],
    'Probabilidad (%)': probas_nn * 100
})

# Ordenar de mayor a menor
df_probs = df_probs.sort_values(by='Probabilidad (%)', ascending=False).reset_index(drop=True)

# Mostrar tabla
import pandas as pd
from IPython.display import display
pd.set_option('display.float_format', '{:.2f}'.format)

print(f"\nDistribución de probabilidades para entrada dada (Red Neuronal Óptima):")
display(df_probs)

# Verificación de suma
print(f"\nSuma total de probabilidades: {df_probs['Probabilidad (%)'].sum():.2f}%")

filtro_real = df_final[
    (df_final['dia_semana_cod'] == entrada['dia_semana_cod']) &
    (df_final['turno_cod'] == entrada['turno_cod']) &
    (df_final['sector_cod'] == entrada['sector_cod']) &
    (df_final['zona_cod'] == entrada['zona_cod'])
]

print(f"Registros encontrados con condiciones similares: {len(filtro_real)}")

# Agrupar por grupo incidente y contar ocurrencias
top_real = filtro_real['grupo_incidente'].value_counts().head(10).reset_index()
top_real.columns = ['Grupo incidente', 'Cantidad de ocurrencias']

print("\nTop-5 incidentes reales más frecuentes en esas condiciones:")
display(top_real)

"""# SHAP Y LINE"""

pip install shap

import shap
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Lambda

# 1. Cargar modelo ya entrenado
modelo_nn_optimo = load_model("modelos/modelo_nn_optimo.keras")

# 2. Preparar datos como en el entrenamiento
categorical_cols = ['turno_cod', 'sector_cod', 'zona_cod', 'dia_semana_cod']
numeric_cols = ['año', 'mes', 'día', 'es_fin_semana']

X_cat_val = df_final[categorical_cols].astype('int32')
X_num_val = df_final[numeric_cols].astype('float32')

# 3. Convertir inputs a numpy arrays
cat_inputs = [X_cat_val[col].to_numpy().reshape(-1, 1)[:100] for col in categorical_cols]
num_input = X_num_val.to_numpy()[:100]

# 4. Concatenar todo para usarlo como una sola entrada para SHAP
X_shap = np.concatenate(cat_inputs + [num_input], axis=1)

# 5. Crear modelo wrapper que reciba una sola entrada y lo separe internamente
input_concat = Input(shape=(X_shap.shape[1],))

# Particionar manualmente las entradas (4 categóricas de 1D + 4 numéricas)
splits = []
idx = 0
for col in categorical_cols:
    # Usar Lambda para expandir dimensión
    splits.append(Lambda(lambda x, i=idx: tf.expand_dims(x[:, i], axis=-1))(input_concat))
    idx += 1
# Agregar las columnas numéricas como último bloque
splits.append(Lambda(lambda x: x[:, idx:])(input_concat))

# Pasar las divisiones al modelo original
output = modelo_nn_optimo(splits)
modelo_envuelto = Model(inputs=input_concat, outputs=output)

import shap
import matplotlib.pyplot as plt

# Calcular los valores SHAP
explainer = shap.Explainer(modelo_envuelto, X_shap)
shap_values = explainer(X_shap)

shap.summary_plot(
    shap_values,
    features=X_shap,
    feature_names=categorical_cols + numeric_cols,
    plot_size=(10, 6),
    max_display=8,
    show=True
)

pip install lime

from lime.lime_tabular import LimeTabularExplainer
import numpy as np

# 1. Preparar datos (X_all como referencia global del entrenamiento)
X_cat_all = df_final[categorical_cols].astype('int32')
X_num_all = df_final[numeric_cols].astype('float32')
X_all = np.hstack([X_cat_all.values, X_num_all.values])

# 2. Obtener número total de clases y lista de nombres reales
num_classes = len(mapa_grupo_incidente)
class_names = [mapa_grupo_incidente.get(i, f"Clase {i}") for i in range(num_classes)]

# 3. Crear explainer con nombres reales
explainer = LimeTabularExplainer(
    training_data=X_all,
    feature_names=categorical_cols + numeric_cols,
    class_names=class_names,
    mode='classification'
)

# 4. Preparar entrada a explicar (ejemplo real)
entrada_real = transformar_input_real(
    año=2025,
    mes=6,
    día=14,
    nombre_dia='Viernes',
    turno='Tarde',
    sector_nombre='Sto.Dominguito'
)

entrada_array = np.hstack([
    np.array([[entrada_real[col]] for col in categorical_cols]).astype('int32').T,
    np.array([[entrada_real[col]] for col in numeric_cols]).astype('float32').T
])

# 5. Definir función adaptada para LIME
def predict_fn(x):
    cat_inputs = [x[:, i].astype('int32') for i in range(len(categorical_cols))]
    num_input = x[:, len(categorical_cols):].astype('float32')
    cat_inputs = [arr.reshape(-1, 1) for arr in cat_inputs]
    input_lime = cat_inputs + [num_input]
    return modelo_nn_optimo.predict(input_lime)

# 6. Explicar la instancia con LIME
exp = explainer.explain_instance(
    data_row=entrada_array[0],
    predict_fn=predict_fn,
    num_features=8,
    top_labels=14
)

import matplotlib.pyplot as plt

# Paleta de colores personalizada para cada clase
custom_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # azul, naranja, verde, rojo, púrpura

# Para cada clase del Top-5
for i, class_id in enumerate(exp.top_labels[:5]):
    fig, ax = plt.subplots(figsize=(7, 5))
    explanation = exp.as_list(label=class_id)

    # Desempaquetar variables y pesos
    features = [x[0] for x in explanation]
    weights = [x[1] for x in explanation]

    # Colores todos iguales para esa clase
    color = custom_colors[i % len(custom_colors)]
    bar_colors = [color] * len(weights)

    # Dibujar barras
    ax.barh(features, weights, color=bar_colors)
    ax.set_title(f"Importancia local para clase: {exp.class_names[class_id]}")
    ax.axvline(0, color='black', linewidth=0.5)
    ax.invert_yaxis()
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.tight_layout()
    plt.show()

"""# test sesgos"""

# Obtener predicciones de probabilidad
preds_prob = modelo_nn_optimo.predict([X_cat_val.to_numpy()[:100, i] for i in range(4)] + [X_num_val.to_numpy()[:100]])

# Obtener los top-5 por fila (de mayor a menor)
top5_preds = np.argsort(preds_prob, axis=1)[:, -5:][:, ::-1]

# Convertir a DataFrame para análisis
tops_df = pd.DataFrame(top5_preds, columns=[f'Top{i+1}' for i in range(5)])
tops_df_melted = tops_df.melt(var_name='Ranking', value_name='Clase predicha')
tops_df_melted['Nombre'] = tops_df_melted['Clase predicha'].map(mapa_grupo_incidente)

# Graficar frecuencias por nombre de clase en top-5
plt.figure(figsize=(10, 5))
sns.countplot(y='Nombre', data=top5_df_melted, order=top5_df_melted['Nombre'].value_counts().index)
plt.title("Distribución de clases predichas (Top-5)")
plt.xlabel("Frecuencia")
plt.ylabel("Clase")
plt.tight_layout()
plt.show()

# Obtener proporciones reales
real_dist = df_final['grupo_incidente_cod'].map(mapa_grupo_incidente).value_counts(normalize=True)

# Obtener proporciones predichas (Top-5)
top5_flat = top5_df_melted['Clase predicha'].map(mapa_grupo_incidente)
top5_pred_dist = top5_flat.value_counts(normalize=True)

# Crear tabla comparativa
comp_top5_df = pd.DataFrame({
    'Real': real_dist,
    'Predicho_Top5': top5_pred_dist
}).fillna(0).sort_values('Real', ascending=False)

display(comp_top5_df.head(14))

import seaborn as sns
import matplotlib.pyplot as plt

# Crear nuevo DataFrame solo con los 100 datos usados en SHAP/predicción
df_pred_100 = df_final.iloc[:100].copy()
df_pred_100['Predicho'] = top1_preds
df_pred_100['Predicho_nombre'] = df_pred_100['Predicho'].map(mapa_grupo_incidente)

# Graficar frecuencia de predicciones por turno
plt.figure(figsize=(8,5))
sns.countplot(data=df_pred_100, x='turno_cod', hue='Predicho_nombre')
plt.title("Distribución de clases predichas por turno")
plt.xlabel("Turno (codificado)")
plt.ylabel("Frecuencia")
plt.legend(title="Clase predicha", bbox_to_anchor=(1,1))
plt.tight_layout()
plt.show()